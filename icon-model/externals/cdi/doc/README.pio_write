The program tests/pio_write is used to

1. generate various synthetic outputs including a checksum for
   correctness testing and
2. can also be used to synthetically create ECHAM-like output files for
   e.g. benchmarks.

For the first purpose everything needed is contained in the various
*_run scripts in the tests directory.

For the second the following option command-line switches are important:

-c

  Disable computation of checksums. This switch is crucial to measure
  run-time for output. It is also needed for MPI-parallel runs to
  achieve load-balance among the client processes since otherwise rank 0
  will perform a gather operation on each and every array written to
  also update a checksum value.

-f FMT

  Switch output file format. The following formats are recognized:

    nc2
    netCDF v2.x format

    nc
    netCDF v3.x format

    nc4
    netCDF v4.x HDF5-based format

    grb
    GRIB 1 format

    ext
    8byte IEEE-fp number legacy Fortran unformatted records
    MPIOM/HOPE EXTRA

    svc
    8byte SERVICE legacy Fortran unformatted records

    ieg
    8byte IEG legacy Fortran unformatted records

  Currently only nc, nc2, nc4 and grb are supported in MPI-parallel mode.

-m LONS, -n LATS, -z LEVS

  Set grid size to LONS x LATS x LEVS. The number of levels is special
  in that only a quarter of the variables will use the full number of
  z levels (see option -s).
  Default: 12 x 6 x 5

-y NVARS

  Set number of variables to synthesize. Must be less than 128.
  Default: 5

-t NTSTEPS

  Set number of timesteps, i.e. number of repetitions.
  Default: 3

-s SEED

  Set seed of PRNG used to generate variable sizes. To have a better
  test coverage, the program will normally use a time-of-day-dependent
  seed and, on average, generate 1/4 of each of the following:
  1. surface level variables (z-size = 1)
  2. intermediate variables (z-size = floor(LEVS/3))
  3. JSBACH-like variables (z-size = min(LEVS, 11))
  4. full 3D variables (z-size = LEVS)

  Setting this seed is currently the only means to influence this
  distribution.

MPI-mode-only flags:

-w NUMSERVERS

  Use NUMSERVERS processes as I/O servers, the rest becomes clients. The
  ranks of the I/O servers will be the highest numbered from MPI_COMM_WORLD.
  Default: 2

-p

  Select from available write modes:

    PIO_NONE

    Run without I/O servers, currently only useable with a single MPI-task.

    PIO_MPI

    Each I/O server process writes individually with MPI_File_iwrite_shared.

    PIO_WRITER

    NUMSERVERS - 1 processes will collect data from clients, 1 is sent the
    encoded records and writes to disk via POSIX functions.

    PIO_ASYNCH

    same as PIO_WRITER but asynchronous I/O functions are used.

    PIO_FPGUARD

    NUMSERVERS - 1 processes write to the file(s) in non-overlapping
    fashion via POSIX seek(2) and write(2).

    PIO_MPI_FW_ORDERED, PIO_MPI_FW_AT_ALL

    All NUMSERVERS processes perform collective writes with
    MPI_File_write_ordered and MPI_File_write_at_all respectively.

  Default: PIO_MPI

The program will write to two files named example_0.$SUFFIX and
example_1.$SUFFIX in sequence, each composed of variables over NTSTEPS
time steps to the current working directory.

The following long options exist to further tune the program behaviour:

-qcache-redists[=(true|false)], -qno-cache-redists[=(true|false)]

Takes optionally =true or =false as argument, (=true is assumed if no
argument is specified). If true (the default), YAXT redist descriptors
are cached. Since data decomposition changes for dynamically
repartitioning models, it might be beneficial for tests of
load-balanced applications to turn this off.

-qpio-role-scheme=(last|first|balanced)

Use this option to change which MPI processes become I/O servers:

In the default configuration (last), it's the highest-ranking processes,
for "first", ranks 0-NUMSERVERS-1 become I/O servers and in the case
"balanced" it's those processes for which rank % NUMSERVERS == 0

-qcreate-uuid[=(true|false)], -qno-create-uuid[=(true|false)]

Use this option to generate UUID for the created grids/zaxis data structures.
This feature is off by default.

-quse-dist-grid[=(true|false)], -qno-use-dist-grid[=(true|false)]

If true, generate a distributed grid on the I/O clients and servers. This
feature is only available when CDI was built with a PPM library including
the distributed multi-array feature.

-qtaxis-type=(absolute|relative|forecast)

Create a time axis following the conventions of TAXIS_ABSOLUTE,
TAXIS_RELATIVE or TAXIS_FORECAST respectively.

-qtaxis-unit=<UNIT>

Set the time unit to one of

* second
* minute
* quarter
* 30minutes
* hour
* 3hours
* 6hours
* 12hours
* day
* month
* year

As with -qtaxis-type see the CDI library documentation for specifics.

-qdatatype=<DATATYPE>

Set the external representation of the written data. Valid values for
DATATYPE are pack followed by the number of significant bits for GRIB
and GRIB2 data and flt32 or flt64 for the other file formats (which
store raw floating point values) to use 32 and 64 bit float formats.
Note: this option must follow the -f option to become effective.
