#! /bin/bash
#-----------------------------------------------------------------------------
set +x

#-----------------------------------------------------------------------------
#
# ICON run script:
# !ATTENTION! Do not change the format of the following lines.
#             They are evaluated by checksuite scripts.
# created by /home/primrose/Work/IconGrounds/icon-dace/icon-scratchpad/icon-model/build/verification/run/make_target_runscript
# target machine is default
# target use_compiler is gcc
# with_mpi=no
# with_openmp=no
# memory_model=large
# submit with 
#
builder=default_gcc
#-----------------------------------------------------------------------------
#
# OpenMP environment variables
# ----------------------------
export OMP_NUM_THREADS=1
export ICON_THREADS=1
export OMP_SCHEDULE=static
export OMP_DYNAMIC="false"
export OMP_STACKSIZE=200M
#
# MPI variables
# -------------
: ${no_of_nodes:=1} ${mpi_procs_pernode:=1}
export no_of_nodes
export mpi_procs_pernode
num_io_procs=
((mpi_total_procs=no_of_nodes * mpi_procs_pernode))
#
# blocking length
# ---------------
nproma=48
nproma_sub=48
nblocks_c=0
proc0_shift=0
#
# Ecrad solver (0 for CPU/vector, 2 for GPU)
# ------------------------------------------
radiation_ecrad_isolver=0
#
#-----------------------------------------------------------------------------

# load local setting, if existing
# -------------------------------
if [ -a /home/primrose/Work/IconGrounds/icon-dace/icon-scratchpad/icon-model/build/verification/setting ]
then
  echo "Load Setting"
  . /home/primrose/Work/IconGrounds/icon-dace/icon-scratchpad/icon-model/build/verification/setting
fi

# environment variables for the experiment and the target system
# --------------------------------------------------------------
export EXPNAME="offline_sediment"

#-----------------------------------------------------------------------------
# directories with absolute paths
# -------------------------------
thisdir=$(pwd)
export basedir="/home/primrose/Work/IconGrounds/icon-dace/icon-scratchpad/icon-model/build/verification"
# experiments_dir can be predefined in a machine specific run_target_* header
experiments_dir="${experiments_dir:=${basedir}/experiments}"
export icon_data_rootFolder="/home/primrose/pool/data/ICON"

# how to start the icon model
# ---------------------------
export START=""
export MODEL="/home/primrose/Work/IconGrounds/icon-dace/icon-scratchpad/icon-model/build/verification/bin/icon"

set | grep SLURM

# how to submit the next job
# --------------------------
submit=""
job_name="exp.offline_sediment.run"

# cdo for post-processing
# -----------------------
cdo="cdo"
cdo_diff="cdo diffn"

# define script functions used in the experiment run script
# ---------------------------------------------------------
. ${basedir}/run/add_run_routines

#-----------------------------------------------------------------------------

#!/bin/bash

# ICON
#
# ------------------------------------------
# Copyright (C) 2004-2024, DWD, MPI-M, DKRZ, KIT, ETH, MeteoSwiss
# Contact information: icon-model.org
# See AUTHORS.TXT for a list of authors
# See LICENSES/ for license information
# SPDX-License-Identifier: BSD-3-Clause
# ------------------------------------------

#=============================================================================
#
# This script runs the offline sediment spinup for Hamocc
#
#-----------------------------------------------------------------------------
# the namelist filename
ocean_namelist=NAMELIST_${EXPNAME}

nproma=16

# global timing
start_date="1000-01-01T00:00:00Z"
  end_date="9000-01-01T00:00:00Z"
#-----------------------------------------------------------------------------

# model timing
restart_interval="P4000Y"             # 4000 years take < 1 hour on 8 compute notes (R2B4)
checkpoint_interval="P4000Y"          # Need to set from_restart="no" after first run, as otherwise
                                      # sediment from reference file is loaded again!

offline_sediment="yes"
from_restart="yes"     # if yes: the sediment is initialized with sediment from reference run 
                       # if no: starts with empty sediment or continues the current run
                       #        (if isRestartRun.sem is present)


#### references and init
# Reference run includes full ocean+hamocc
# The sediment reference file has to have yearly mean data!
# There can only be 1 timestep in the sediment reference file!
reference_exp=ler0707        # id of reference experiment
reference_year=3700          # year for fluxes and restart of reference run
ocean_reference_folder="/work/mh0727/m300732/input/example_data"
ocean_reference_flux_filename="${reference_exp}_hamocc_sediment_${reference_year}0101T000000Z.nc"
ocean_restart_folder="/work/mh0727/m300732/input/example_data"
ocean_reference_restart_filename=${reference_exp}"_restart_oce_${reference_year}0101T000000Z.nc"
#
#-----------------------------------------------------------------------------
output_interval="P10Y"                  # 10 year output or less is sufficient
file_interval="P2000Y"


modelTimeStep="PT24H"   # 24 hours

autoPostProcessing="false"                         # submit postprocessing job

#-----------------------------------------------------------------------------
# global resolution

ocean_vertical_levels=40

ocean_gridID="0036"
ocean_refinement="R02B04"
ocean_grid_name="icon_grid_${ocean_gridID}_${ocean_refinement}_O"
ocean_grid=${ocean_grid_name}.nc
ocean_grid_folder="/pool/data/ICON/grids/public/mpim/${ocean_gridID}"
ocean_data_InputFolder="/pool/data/ICON/oes/input/r0004/${ocean_grid_name}"

# HAMOCC
lhamocc=".true."
lbgcadv=".true."
loffsed=".true."

#-----------------------------------------------------------------------------
#
# write namelist parameters
# -------------------------
cat > ${ocean_namelist} << EOF
!
&parallel_nml
 nproma         = $nproma
 p_test_run     = .false.
 l_fast_sum     = .false.
 num_prefetch_proc = 0 
 pio_type       = 0
 num_io_procs   = 0
/
&grid_nml
 dynamics_grid_filename = "${ocean_grid}"
 use_dummy_cell_closure      = .TRUE.
 use_duplicated_connectivity = .FALSE.
/
&run_nml
 modelTimeStep               = "${modelTimeStep}"
 output                      = 'nml'                            ! namelist controlled output scheme
 activate_sync_timers        = .TRUE.
 profiling_output            = 2                                ! aggregated: 1; detailed: 2; in files: 3
 msg_timestamp               = .FALSE.
 timers_level                = 10
 debug_check_level           = 1
 restart_filename            = "${EXPNAME}_restart_oce_<rsttime>.nc"
/
&output_nml
  filetype         =  4                       ! output format: 2=GRIB2, 4=NETCDFv2
  filename_format  = "<output_filename>_<datetime2>"
  output_filename  = "${EXPNAME}_hamocc_sediment"
  output_start     = "${start_date}"                  ! start in ISO-format
  output_end       = "${end_date}"                    ! end in ISO-format
  output_interval  = "${output_interval}"
  file_interval    = "${file_interval}"
  output_grid      = .TRUE.
  mode             = 1
  operation        = 'mean'
  ml_varlist       =  'group:HAMOCC_SED'
/

&dbg_index_nml
  idbg_mxmn                  = 1                                ! initialize MIN/MAX  debug output
  idbg_val                   = 0                                ! initialize one cell debug output
  idbg_slev                  = 1                                ! initialize start level for debug output
  idbg_elev                  = 5                                ! initialize end level for debug output
  dbg_lat_in                 = 30.0                             ! latitude location of one cell debug output
  dbg_lon_in                 = -30.0                            ! longitude location of one cell debug output
  str_mod_tst                ='oceanCouplng'                    ! define modules to print out in debug mode
  str_mod_tst                = 'all'                            ! define modules to print out in debug mode
/
&ocean_dynamics_nml
! 40 unevenly spaced levels used by MPIOM/GR30
 n_zlev             =   $ocean_vertical_levels
 dzlev_m(1:40)      =   12.0,   10.0,   10.0,   10.0,   10.0,   10.0,   13.0,   15.0,   20.0,   25.0,
                        30.0,   35.0,   40.0,   45.0,   50.0,   55.0,   60.0,   70.0,   80.0,   90.0,
                       100.0,  110.0,  120.0,  130.0,  140.0,  150.0,  170.0,  180.0,  190.0,  200.0,
                       220.0,  250.0,  270.0,  300.0,  350.0,  400.0,  450.0,  500.0,  500.0,  600.0
  l_edge_based                    = .FALSE.   ! edge- or cell-based mimetic discretization
  l_partial_cells                 = .FALSE.   ! partial bottom cells=true: local varying bottom depth
/
&ocean_physics_nml
  lhamocc                                    = ${lhamocc}
  lbgcadv                                    = ${lbgcadv}
  lsediment_only                             = ${loffsed}
/                                           
&sea_ice_nml
  stress_ice_zero = .TRUE.
/
&hamocc_nml
l_cpl_co2                         = .FALSE.
l_bgc_check                       = .FALSE.   ! mass check at every time step
l_implsed                         = .FALSE.    ! implicit sediment formulation
l_init_bgc                        = .FALSE.
hion_solver                       = 1
/
EOF
#
if [ "x${from_restart}" = "xyes" ]; then
cat >> ${ocean_namelist} << EOF
&ocean_initialConditions_nml
  initial_salinity_type                      = 0                ! 0: none, 1: read S from initial_state.nc
  initial_temperature_type                   = 0                ! 0: none, 1: read T from initial_state.nc
  initialize_fromRestart                     = .TRUE.
/
EOF
else
cat >> ${ocean_namelist} << EOF
&ocean_initialConditions_nml
  initial_salinity_type                      = 0                ! 0: none, 1: read S from initial_state.nc
  initial_temperature_type                   = 0                ! 0: none, 1: read T from initial_state.nc
  initialize_fromRestart                     = .FALSE.
/
EOF
fi
#
cat >> ${ocean_namelist} << EOF
&io_nml
  lkeep_in_sync                              = .TRUE.           ! sync after each timestep
/
EOF

add_required_file ${basedir}/run/${ocean_namelist} ./

#-----------------------------------------------------------------------------
#
# Ocean grid
#
add_required_file ${ocean_grid_folder}/${ocean_grid} ./
#

# surface boundary condition
add_link_file ${ocean_data_InputFolder}/R2B4_ocean-flux.nc     ocean-flux.nc
add_link_file ${ocean_data_InputFolder}/R2B4_ocean-relax.nc    ocean-relax.nc



## HAMOCC forcing files
#

# fluxes into sediment
# FIXME: this is still a private path
add_link_file ${ocean_reference_folder}/${ocean_reference_flux_filename} particle_fluxes.nc

# initital state for sediment
if [  "x${from_restart}"  = "xyes" ]; then
  add_link_file ${ocean_restart_folder}/${ocean_reference_restart_filename} restart_oce_DOM01.nc
fi
#
#-----------------------------------------------------------------------------
# ICON
#
# ---------------------------------------------------------------
# Copyright (C) 2004-2024, DWD, MPI-M, DKRZ, KIT, ETH, MeteoSwiss
# Contact information: icon-model.org
# See AUTHORS.TXT for a list of authors
# See LICENSES/ for license information
# SPDX-License-Identifier: BSD-3-Clause
# ---------------------------------------------------------------

#=============================================================================
#
# This section of the run script prepares and starts the model integration. 
#
# MODEL and START must be defined as environment variables or
# they must be substituted with appropriate values.
#
# Marco Giorgetta, MPI-M, 2010-04-21
#
#-----------------------------------------------------------------------------
final_status_file=${basedir}/run/${job_name}.final_status
rm -f ${final_status_file}
#-----------------------------------------------------------------------------
#
# directories definition
#
RUNSCRIPTDIR=${basedir}/run
if [ x$grids_folder = x ] ; then
   HGRIDDIR=${basedir}/grids
else
   HGRIDDIR=$grids_folder
fi

make_and_change_to_experiment_dir

for dir in ${ADDITIONAL_SUBDIRS[@]}; do
  mkdir -p $dir
done

#-----------------------------------------------------------------------------
final_status_file=${RUNSCRIPTDIR}/${job_name}.final_status
rm -f ${final_status_file}

#-----------------------------------------------------------------------------
# set up the model lists if they do not exist
# this works for single model runs
# for coupled runs the lists should be declared explicilty
if [ x$namelist_list = x ]; then
#  minrank_list=(        0           )
#  maxrank_list=(     65535          )
#  incrank_list=(        1           )
  minrank_list[0]=0
  maxrank_list[0]=65535
  incrank_list[0]=1
  if [ x$atmo_namelist != x ]; then
    # this is the atmo model
    namelist_list[0]="$atmo_namelist"
    modelname_list[0]="atm"
    modeltype_list[0]=1
    run_atmo="true"
  elif [ x$ocean_namelist != x ]; then
    # this is the ocean model
    namelist_list[0]="$ocean_namelist"
    modelname_list[0]="oce"
    modeltype_list[0]=2
  elif [ x$psrad_namelist != x ]; then
    # this is the psrad model
    namelist_list[0]="$psrad_namelist"
    modelname_list[0]="psrad"
    modeltype_list[0]=3
  elif [ x$hamocc_namelist != x ]; then
    # this is the hamocc model
    namelist_list[0]="$hamocc_namelist"
    modelname_list[0]="hamocc"
    modeltype_list[0]=4
  elif [ x$jsbach_namelist != x ]; then
    # this is the jsbach standalone model
    namelist_list[0]="$jsbach_namelist"
    modelname_list[0]="jsbach"
    modeltype_list[0]=5
    run_jsbach_standalone="true"
  elif [ x$testbed_namelist != x ]; then
    # this is the testbed model
    namelist_list[0]="$testbed_namelist"
    modelname_list[0]="testbed"
    modeltype_list[0]=99
  else
    check_error 1 "No namelist is defined"
  fi 
fi

#-----------------------------------------------------------------------------


#-----------------------------------------------------------------------------
# set some default values and derive some run parameteres
restart=${restart:=".false."}
restartSemaphoreFilename='isRestartRun.sem'
#AUTOMATIC_RESTART_SETUP:
if [ -f ${restartSemaphoreFilename} ]; then
  restart=.true.
  #  do not delete switch-file, to enable restart after unintended abort
  #[[ -f ${restartSemaphoreFilename} ]] && rm ${restartSemaphoreFilename}
fi
#END AUTOMATIC_RESTART_SETUP
#
# wait 5min to let GPFS finish the write operations
if [ "x$restart" != 'x.false.' -a "x$submit" != 'x' ]; then
  if [ x$(df -T ${EXPDIR} | cut -d ' ' -f 2) = gpfs ]; then
    sleep 10;
  fi
fi
# fill some checks

run_atmo=${run_atmo="false"}
if [ x$atmo_namelist != x ]; then
  run_atmo="true"
  run_jsbach_standalone="false"
fi
run_jsbach=${run_jsbach="false"}
if [ x$jsbach_namelist != x ]; then
  run_jsbach="true"
fi
run_ocean=${run_ocean="false"}
if [ x$ocean_namelist != x ]; then
  run_ocean="true"
fi
run_psrad=${run_psrad="false"}
if [ x$psrad_namelist != x ]; then
  run_psrad="true"
fi
run_hamocc=${run_hamocc="false"}
if [ x$hamocc_namelist != x ]; then
  run_hamocc="true"
fi

#-----------------------------------------------------------------------------
# add grids to required files
all_grids="${atmo_dyn_grids} ${atmo_rad_grids} ${ocean_grids}"
for gridfile in ${all_grids}; do
  #
  gridfile=${gridfile//\'/} # strip all ' in case ' is used to delimit the grid names
  gridfile=${gridfile//\"/} # strip all " in case " is used to delimit the grid names
  gridfile=${gridfile//\,/} # strip all , in case , is used to separate the grid names
  #
  grfinfofile=${gridfile%.nc}-grfinfo.nc
  #
  ls -l ${HGRIDDIR}/$gridfile
  check_error $? "${HGRIDDIR}/$gridfile does not exist."
  add_link_file ${HGRIDDIR}/${gridfile} ./
  if [ -f ${HGRIDDIR}/${grfinfofile} ]; then    
    add_link_file ${HGRIDDIR}/${grfinfofile} ./
  fi
done
#-----------------------------------------------------------------------------
# print_required_files
copy_required_files
link_required_files


#-----------------------------------------------------------------------------
# get restart files

if  [ x$restart_atmo_from != "x" ] ; then
  rm -f restart_atm_DOM01.nc
#  ln -s ${basedir}/experiments/${restart_from_folder}/${restart_atmo_from} ${EXPDIR}/restart_atm_DOM01.nc
  cp ${basedir}/experiments/${restart_from_folder}/${restart_atmo_from} cp_restart_atm.nc
  ln -s cp_restart_atm.nc restart_atm_DOM01.nc
  restart=".true."
fi
if  [ x$restart_ocean_from != "x" ] ; then
  rm -f restart_oce.nc
#  ln -s ${basedir}/experiments/${restart_from_folder}/${restart_ocean_from} ${EXPDIR}/restart_oce.nc
  cp ${basedir}/experiments/${restart_from_folder}/${restart_ocean_from} cp_restart_oce_DOM01.nc
  ln -s cp_restart_oce_DOM01.nc restart_oce_DOM01.nc
  restart=".true."
fi
#-----------------------------------------------------------------------------


read_restart_namelists=${read_restart_namelists:=".true."}

#-----------------------------------------------------------------------------
#
# create ICON master namelist
# ------------------------
# For a complete list see Namelist_overview and Namelist_overview.pdf

#-----------------------------------------------------------------------------
# create master_namelist
if [ -z "$dont_create_icon_master_namelist" ]; then
  master_namelist=icon_master.namelist

  calendar=${calendar:="proleptic gregorian"}
  calendar_type=${calendar_type:=1}
  {
    echo "&master_nml"
    echo " lrestart               =  $restart"
    echo " read_restart_namelists =  $read_restart_namelists"
    echo "/"

    if [ -z "$nsteps" ]; then
      echo "&master_time_control_nml"
      echo " calendar             = '$calendar'"
      echo " experimentStartDate  = '$start_date'"
      echo " restartTimeIntval    = '$restart_interval'"
      echo " checkpointTimeIntval = '$checkpoint_interval'"
      if [ -n "$end_date" ]; then
        echo " experimentStopDate = '$end_date'"
      fi
      echo "/"

      echo "&time_nml"
      echo " is_relative_time     = .false."
      echo "/"

    else # $nsteps is set -> use time_nml:ini_datetime_string
      echo "&time_nml"
      echo " calendar             =  $calendar_type"
      echo " ini_datetime_string  = '$start_date'"
      echo " dt_restart           =  $dt_restart"
      echo "/"
    fi
  } > $master_namelist

fi
#-----------------------------------------------------------------------------


#-----------------------------------------------------------------------------
# add model component to master_namelist
add_component_to_master_namelist()
{
  model_namelist_filename=$1
  if [ x${dont_create_icon_master_namelist+set} != xset ]; then
    model_name=$2
    model_type=$3
    model_min_rank=$4
    model_max_rank=$5
    model_inc_rank=$6
    model_rank_group_size=$7
    cat >> $master_namelist << EOF
&master_model_nml
  model_name="$model_name"
  model_namelist_filename="$model_namelist_filename"
  model_type=$model_type
  model_min_rank=$model_min_rank
  model_max_rank=$model_max_rank
  model_inc_rank=$model_inc_rank
  model_rank_group_size=$model_rank_group_size
/
EOF
  fi

  #-----------
  #get namelist
  if [ -f ${RUNSCRIPTDIR}/$model_namelist_filename ] ; then
    mv -f ${RUNSCRIPTDIR}/$model_namelist_filename ${EXPDIR}
    check_error $? "mv -f ${RUNSCRIPTDIR}/$model_namelist_filename ${EXPDIR}"
  else
    check_error 1 "${RUNSCRIPTDIR}/$model_namelist_filename does not exist"
  fi
}
#-----------------------------------------------------------------------------


no_of_models=${#namelist_list[*]}
echo "no_of_models=$no_of_models"

rank_group_size=1
j=0
while [ $j -lt ${no_of_models} ]
do
  add_component_to_master_namelist "${namelist_list[$j]}" "${modelname_list[$j]}" ${modeltype_list[$j]} ${minrank_list[$j]} ${maxrank_list[$j]} ${incrank_list[$j]} ${rank_group_size}
  j=`expr ${j} + 1`
done

#-----------------------------------------------------------------------------
# Add JSBACH part to master_namelist
# For several domains, $jsbach_namelist is only the basename for each domain's jsbach namelist;
#   the actual namelist files are appended by suffixes '_d1', '_d2', etc.

if [[ $run_jsbach == yes  ]] || [[ $run_jsbach == true ]]; then
  cat >> $master_namelist << EOF
&jsb_control_nml
 is_standalone      = .${run_jsbach_standalone:=false}.
 restart_jsbach     = ${restart}
 debug_level        = 0
 timer_level        = 0
/
EOF
#
if [[ -n ${atmo_dyn_grids} ]]; then
  no_of_domains=$(echo ${atmo_dyn_grids} | wc -w)
else
  no_of_domains=1
fi
echo "no_of_domains=$no_of_domains"
domain=""
domain_suffix=""
j=1
while [ $j -le ${no_of_domains} ]
do
  if [[ $no_of_domains -gt 1 ]]; then
    # no_of_domains < 10 !
    domain=" DOM0${j}"
    domain_suffix="_d${j}"
  fi
  cat >> $master_namelist << EOF
&jsb_model_nml
 model_id = $j
 model_name = "JSBACH${domain}"
 model_shortname = "jsb${domain_suffix}"
 model_description = 'JSBACH land surface model'
 model_namelist_filename = "${jsbach_namelist}${domain_suffix}"
/
EOF
  if [[ ${run_jsbach_standalone} != true ]]; then
    if [[ -f ${RUNSCRIPTDIR}/${jsbach_namelist}${domain_suffix} ]] ; then
      mv ${RUNSCRIPTDIR}/${jsbach_namelist}${domain_suffix} ${EXPDIR}
      check_error $? "mv ${RUNSCRIPTDIR}/${jsbach_namelist}${domain_suffix}"
    else
      check_error 1 "${RUNSCRIPTDIR}/${jsbach_namelist}${domain_suffix} does not exist"
    fi
  fi
  j=`expr ${j} + 1`
done
fi

#
#  get model
#
ls -l ${MODEL}
check_error $? "${MODEL} does not exist?"
#
ldd ${MODEL}
#
#-----------------------------------------------------------------------------

#
# configure START_MODEL_function
#
# TODO: be less atmospheric centric, i.e. do not assume that atmosphere is always component 1
ICON_COMPONENT1_VH_procs=$(( ${num_restart_procs:-0} + ${num_io_procs:-0} + ${num_prefetch_proc:-0} + ${num_io_procs_radar:-0}))

#
# start experiment
#

# Combine START and MODEL if START_MODEL is not already set.
# START_MODEL is used to ease the execution of a machine that uses a complex
# mpirun command with multiple binaries
START_MODEL="${START_MODEL:=$START $MODEL}"


rm -f finish.status
#
date
set -x
${START_MODEL} || exit 1
set +x
date
#
if [ -r finish.status ] ; then
  check_final_status 0 "${START} ${MODEL}"
else
  check_final_status -1 "${START} ${MODEL}"
fi
#
#-----------------------------------------------------------------------------
#
finish_status=`cat finish.status`
echo $finish_status
echo "============================"
echo "Script run successfully: $finish_status"
echo "============================"

#-----------------------------------------------------------------------------
# rm output_schedule_steps*
#-----------------------------------------------------------------------------
if [[ "x$use_hamocc" = "xyes" ]]; then
# store HAMOCC log file
strg="$(ls -rt ${EXPNAME}_hamocc_EU*.nc* | tail -1 )"
prefx="${EXPNAME}_hamocc_EU_tendencies"
foo=${strg##${prefx}}
foo=${foo%%.*}
bgcout_file="bgcout_${foo}"
mv bgcout $bgcout_file
fi
#-----------------------------------------------------------------------------
namelist_list=""
#-----------------------------------------------------------------------------
# check if we have to restart, ie resubmit
#   Note: this is a different mechanism from checking the restart
if [ $finish_status = "RESTART" ] ; then
  echo "restart next experiment..."
  this_script="${RUNSCRIPTDIR}/${job_name}"
  echo 'this_script: ' "$this_script"
  touch ${restartSemaphoreFilename}
  cd ${RUNSCRIPTDIR}
  ${submit} $this_script $run_param_0
else
  [[ -f ${restartSemaphoreFilename} ]] && rm ${restartSemaphoreFilename}
fi

#-----------------------------------------------------------------------------
# automatic call/submission of post processing if available
if [ "x${autoPostProcessing}" = "xtrue" ]; then
  # check if there is a postprocessing is available
  cd ${RUNSCRIPTDIR}
  targetPostProcessingScript="./post.${EXPNAME}.run"
  [[ -x $targetPostProcessingScript ]] && ${submit} ${targetPostProcessingScript}
  cd -
fi

#-----------------------------------------------------------------------------

cd $RUNSCRIPTDIR

#-----------------------------------------------------------------------------

	
# exit 0
#
# vim:ft=sh
#-----------------------------------------------------------------------------
